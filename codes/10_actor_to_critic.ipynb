{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "import random\n",
    "import numpy as np\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from GridWorld_v1 import GridWorld_v1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAASMAAAEhCAYAAAA06MYmAAAAOXRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjkuMiwgaHR0cHM6Ly9tYXRwbG90bGliLm9yZy8hTgPZAAAACXBIWXMAAA9hAAAPYQGoP6dpAAAH+ElEQVR4nO3ZsW4bZxaG4UPDDUlITEfaSDottjJYE4ZLXUeKlAu486XoalhvnRtgF0CAulDCcCwE8WxhOOY2MumMxC+j56mmmOIczfAFf2rUdV1XACf24tQDAFSJERBCjIAIYgREECMgghgBEcQIiCBGQISXh9z06dOnur6+rrOzsxqNRo89EzAQXdfV3d1dvX79ul68ePi7z0Exur6+rp9++qmX4YDn57fffqsff/zxwXsOitHZ2VlVVf366681n8///mQBdrtdXVxcVFXVZrOpyWRy4on6M9Td7PXPsr/Xl4Y85KAYfTmazefzevXq1d8YL0fTNH9dLxaLmk6nJ5ymX0PdzV7/LPt7HfLzjh+wgQhiBEQQIyCCGAERxAiIIEZABDECIogREEGMgAhiBEQQIyCCGAERxAiIIEZABDECIogREEGMgAhiBEQQIyCCGAERxAiIIEZABDECIogREEGMgAhiBEQQIyCCGAERxAiIIEZABDECIogREEGMgAhiBEQQIyCCGAERxAiIIEZABDECIogREEGMgAhiBEQQIyCCGAERxAiIIEZABDECIogREOHlMTfvdrtqmuaxZnlS+3sMZacvhrqbvf5Zjt1l1HVd962bbm9vazabffdQwPO23W7r/Pz8wXsc04AIRx3TNptNLRaLx5rlSTVNU/P5vKqqrt5XLS9OPFCP2vuqyw+fr4e02/5e6/W6VqvVaQfqyf67eHNzU9Pp9MQT9WN/r0McFaPJZDKYP9S+5UXV2zejU4/Rm6b9evIe0m77e43H40G+i9PpdJB7HcIxDYggRkAEMQIiiBEQQYyACGIERBAjIIIYARHECIggRkAEMQIiiBEQQYyACGIERBAjIIIYARHECIggRkAEMQIiiBEQQYyACGIERBAjIIIYARHECIggRkAEMQIiiBEQQYyACGIERBAjIIIYARHECIggRkAEMQIiiBEQQYyACGIERBAjIIIYARHECIggRkAEMQIiiBEQQYyACGIERBAjIIIYARHECIjw8pibd7tdNU3zWLM8qf092vuqpu1OOE2/mo9fr4e02//t1baDfBeHslPV8buMuq775pt6e3tbs9nsu4cCnrftdlvn5+cP3uOYBkQ46pi22WxqsVg81ixPqmmams/nVVW1Xq9rPB6feKL+tG1bl5eXVVV19b5qeXHigXrS3lddfvh8vV6va7VanXagnuy/izc3NzWdTk88UT/29zrEUTGaTCaD+UPtW61Wg9pr/6y+vKh6+2Z0wmn6s//b13g8HtQz+2I6nQ5yr0M4pgERxAiIIEZABDECIogREEGMgAhiBEQQIyCCGAERxAiIIEZABDECIogREEGMgAhiBEQQIyCCGAERxAiIIEZABDECIogREEGMgAhiBEQQIyCCGAERxAiIIEZABDECIogREEGMgAhiBEQQIyCCGAERxAiIIEZABDECIogREEGMgAhiBEQQIyCCGAERxAiIIEZABDECIogREEGMgAhiBEQQIyCCGAERXh5z8263q6ZpHmuWJ7W/x1B2+mJ/n/a+qmm7E07Tn+bj1+u2bQfz3Ib6Lh67y6jrum++qbe3tzWbzb57KOB52263dX5+/uA9jmlAhKOOaZvNphaLxWPN8qSapqn5fF5VVVfvq5YXJx6oR+191eWHz9f/+vnnevXu3WkH6smf9/f13//8p6qG9cz2n9d6va7VanXagXqy/xk7xFExmkwmNZ1Ojx4q3fKi6u2b0anH6M3+b0Sv3r2rf//yywmn6c8fTfNXjIb0zPaf13g8HuRn7BCOaUAEMQIiiBEQQYyACGIERBAjIIIYARHECIggRkAEMQIiiBEQQYyACGIERBAjIIIYARHECIggRkAEMQIiiBEQQYyACGIERBAjIIIYARHECIggRkAEMQIiiBEQQYyACGIERBAjIIIYARHECIggRkAEMQIiiBEQQYyACGIERBAjIIIYARHECIggRkAEMQIiiBEQQYyACGIERBAjIIIYARHECIggRkCEl8fcvNvtqmmax5rlSe3v0d5XNW13wmn61Xz8ev3n/X39MZBn9sdAn9n+82rbdpCfsUOMuq775hO9vb2t2Wz23UMBz9t2u63z8/MH73FMAyIcdUzbbDa1WCwea5Yn1TRNzefzqqq6el+1vDjxQD1q76suP3y+vrq6quVyedqBetK2bV1eXlZV1Xq9rvF4fOKJ+rG/183NTU2n0xNP1I/9z9ghjorRZDIZzB9q3/Ki6u2b0anH6M3+bynL5bLevn17wmn6s/8bxGq1Gsy7uL/XdDodzF7HckwDIogREEGMgAhiBEQQIyCCGAERxAiIIEZABDECIogREEGMgAhiBEQQIyCCGAERxAiIIEZABDECIogREEGMgAhiBEQQIyCCGAERxAiIIEZABDECIogREEGMgAhiBEQQIyCCGAERxAiIIEZABDECIogREEGMgAhiBEQQIyCCGAERxAiIIEZABDECIogREEGMgAhiBEQQIyCCGAERxAiIIEZABDECIrw85ubdbldN0zzWLE9qf4/2vqppuxNO06/m49frtm0H+cyGslPV89jrEKOu6775Kdxut/XDDz9870zAM/f777/XbDZ78J6Djml3d3e9DAQ8T4c05KBvRp8+farr6+s6Ozur0WjUy3DA8HVdV3d3d/X69et68eLh7z4HxQjgsflvGhBBjIAIYgREECMgghgBEcQIiCBGQIT/Aefc2339KboAAAAAAElFTkSuQmCC",
      "text/plain": [
       "<Figure size 350x350 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "desc = rows = 5  # 记得行数和列数这里要同步改\n",
    "columns = 5\n",
    "desc = [\".....\",\".##..\",\"..#..\",\".#T#.\",\".#...\"]\n",
    "\n",
    "gridworld = GridWorld_v1(forbidden_area_score=-1, score=1,desc=desc) \n",
    "print(gridworld.animator.fig.get_facecolor())\n",
    "gridworld.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "class ValueNet(torch.nn.Module):\n",
    "    \"\"\"只有一层隐藏层的Q网络\"\"\"\n",
    "\n",
    "    def __init__(self,state_dim,hidden_dim):\n",
    "        super().__init__()\n",
    "        self.fc1 = torch.nn.Linear(state_dim, hidden_dim)\n",
    "        self.fc2 = torch.nn.Linear(hidden_dim, 1)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = F.relu(self.fc1(x))  # 隐藏层使用ReLU激活函数\n",
    "        return self.fc2(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "class PolicyNet(torch.nn.Module):\n",
    "    \"\"\"只有一层隐藏层的Q网络\"\"\"\n",
    "\n",
    "    def __init__(self,state_dim,action_dim):\n",
    "        super().__init__()\n",
    "        self.fc1 = torch.nn.Linear(state_dim, 64)\n",
    "        self.fc2 = torch.nn.Linear(64, action_dim)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = F.relu(self.fc1(x))  # 隐藏层使用ReLU激活函数\n",
    "        x = F.relu(self.fc2(x))\n",
    "        return F.softmax(x,dim=1)  # 输出层不使用激活函数"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "class ActorCritic:\n",
    "    def __init__(\n",
    "        self,\n",
    "        state_dim,\n",
    "        action_dim,\n",
    "        hidden_dim,\n",
    "        learning_rate,\n",
    "        critic_rate,\n",
    "        gamma,\n",
    "        device,\n",
    "    ) -> None:\n",
    "        self.action_dim = action_dim\n",
    "        self.policy_net = PolicyNet(state_dim, action_dim).to(device)\n",
    "        self.value_net = ValueNet(state_dim,hidden_dim)\n",
    "\n",
    "        self.actor_optimizer = torch.optim.Adam(self.policy_net.parameters(), lr=learning_rate)\n",
    "        self.critic_optimizer = torch.optim.Adam(self.value_net.parameters(), lr=critic_rate)\n",
    "        self.device = device\n",
    "        self.gamma = gamma\n",
    "\n",
    "    def take_action(self, state:tuple[ int,int ]):\n",
    "        state = torch.tensor([state], dtype=torch.float32).to(self.device)\n",
    "        probs = self.policy_net(state)\n",
    "        action_dist  = torch.distributions.Categorical(probs)\n",
    "        action = action_dist.sample()\n",
    "        return action.item()\n",
    "\n",
    "    def update(self, transiton_dict):\n",
    "        reward_list = transiton_dict[\"rewards\"]\n",
    "        state_list = transiton_dict[\"states\"]\n",
    "        action_list = transiton_dict[\"actions\"]\n",
    "        G = 0\n",
    "        states = torch.tensor(state_list, dtype=torch.float32).to(self.device)\n",
    "        actions = torch.tensor(action_list).view(-1,1).to(self.device)\n",
    "        next_states = torch.tensor(transiton_dict[\"next_states\"], dtype=torch.float32).to(self.device)\n",
    "        rewards = torch.tensor(reward_list,dtype=torch.float32).view(-1,1).to(self.device)\n",
    "        dones = torch.tensor(transiton_dict[\"dones\"], dtype=torch.float32).view(-1,1).to(self.device)\n",
    "        # print(f\"{states.shape=}\")\n",
    "        # print(f\"{actions.shape=}\")\n",
    "        # print(f\"{next_states.shape=}\")\n",
    "        # print(f\"{rewards.shape=}\")\n",
    "\n",
    "        td_target = rewards+self.gamma*self.value_net(next_states)*(1-dones)\n",
    "        # print(f\"{td_target.shape=}\")\n",
    "        td_delta = td_target - self.value_net(states)\n",
    "        # td_delta = -td_target + self.value_net(states)\n",
    "        action_pros = self.policy_net(states)\n",
    "        log_probs = torch.log(action_pros.gather( 1,actions ))\n",
    "        actor_loss = torch.mean(-log_probs*td_delta.detach())\n",
    "        critic_loss = torch.mean(F.mse_loss(self.value_net(states),td_target.detach()))\n",
    "        self.actor_optimizer.zero_grad() # 在这里就清零了\n",
    "        self.critic_optimizer.zero_grad() # 在这里就清零了\n",
    "        actor_loss.backward()\n",
    "        critic_loss.backward()\n",
    "        self.actor_optimizer.step()\n",
    "        self.critic_optimizer.step()\n",
    "\n",
    "    def save(self, path):\n",
    "        torch.save(self.policy_net.state_dict(), path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "lr = 1e-4\n",
    "\n",
    "num_episodes = 10000\n",
    "hidden_dim = 12\n",
    "gamma = 0.99\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "random.seed(0)\n",
    "np.random.seed(0)\n",
    "torch.manual_seed(0)\n",
    "state_dim = 2\n",
    "action_dim = 5\n",
    "hidden_dim = 32\n",
    "\n",
    "agent = ActorCritic(\n",
    "    state_dim,\n",
    "    action_dim,\n",
    "    hidden_dim,\n",
    "    lr,\n",
    "    lr,\n",
    "    gamma,\n",
    "    device,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "episode: 0, value: -7.0\n",
      "episode: 30, value: -19.0\n",
      "episode: 60, value: -12.0\n",
      "episode: 90, value: -12.0\n",
      "episode: 120, value: -8.0\n",
      "episode: 150, value: 1.0\n",
      "episode: 180, value: -1.0\n",
      "episode: 210, value: -6.0\n",
      "episode: 240, value: 1.0\n",
      "episode: 270, value: -11.0\n",
      "episode: 300, value: -8.0\n",
      "episode: 330, value: 1.0\n",
      "episode: 360, value: -6.0\n",
      "episode: 390, value: 1.0\n",
      "episode: 420, value: -6.0\n",
      "episode: 450, value: -5.0\n",
      "episode: 480, value: -3.0\n",
      "episode: 510, value: 0.0\n",
      "episode: 540, value: 0.0\n",
      "episode: 570, value: -88.0\n",
      "episode: 600, value: -37.0\n",
      "episode: 630, value: -26.0\n",
      "episode: 660, value: -16.0\n",
      "episode: 690, value: 1.0\n",
      "episode: 720, value: -1.0\n",
      "episode: 750, value: -24.0\n",
      "episode: 780, value: -5.0\n",
      "episode: 810, value: -20.0\n",
      "episode: 840, value: -65.0\n",
      "episode: 870, value: -3.0\n",
      "episode: 900, value: -10.0\n",
      "episode: 930, value: -92.0\n",
      "episode: 960, value: -38.0\n",
      "episode: 990, value: -4.0\n",
      "episode: 1020, value: -7.0\n",
      "episode: 1050, value: -108.0\n",
      "episode: 1080, value: -28.0\n",
      "episode: 1110, value: -22.0\n",
      "episode: 1140, value: -17.0\n",
      "episode: 1170, value: -19.0\n",
      "episode: 1200, value: -13.0\n",
      "episode: 1230, value: -226.0\n",
      "episode: 1260, value: -20.0\n",
      "episode: 1290, value: -26.0\n",
      "episode: 1320, value: -92.0\n",
      "episode: 1350, value: 0.0\n",
      "episode: 1380, value: -16.0\n",
      "episode: 1410, value: -21.0\n",
      "episode: 1440, value: -4.0\n",
      "episode: 1470, value: -2.0\n",
      "episode: 1500, value: -130.0\n",
      "episode: 1530, value: 1.0\n",
      "episode: 1560, value: -188.0\n",
      "episode: 1590, value: -92.0\n",
      "episode: 1620, value: -49.0\n",
      "episode: 1650, value: 0.0\n",
      "episode: 1680, value: -100.0\n",
      "episode: 1710, value: -35.0\n",
      "episode: 1740, value: -52.0\n",
      "episode: 1770, value: -3.0\n",
      "episode: 1800, value: -34.0\n",
      "episode: 1830, value: -64.0\n",
      "episode: 1860, value: 0.0\n",
      "episode: 1890, value: 0.0\n",
      "episode: 1920, value: -136.0\n",
      "episode: 1950, value: 1.0\n",
      "episode: 1980, value: -9.0\n",
      "episode: 2010, value: 0.0\n",
      "episode: 2040, value: -53.0\n",
      "episode: 2070, value: -50.0\n",
      "episode: 2100, value: -125.0\n",
      "episode: 2130, value: -201.0\n",
      "episode: 2160, value: -49.0\n",
      "episode: 2190, value: -69.0\n",
      "episode: 2220, value: -86.0\n",
      "episode: 2250, value: -35.0\n",
      "episode: 2280, value: -145.0\n",
      "episode: 2310, value: -219.0\n",
      "episode: 2340, value: -72.0\n",
      "episode: 2370, value: -22.0\n",
      "episode: 2400, value: -81.0\n",
      "episode: 2430, value: -145.0\n",
      "episode: 2460, value: -127.0\n",
      "episode: 2490, value: -22.0\n",
      "episode: 2520, value: -102.0\n",
      "episode: 2550, value: -26.0\n",
      "episode: 2580, value: -173.0\n",
      "episode: 2610, value: -151.0\n",
      "episode: 2640, value: -44.0\n",
      "episode: 2670, value: -251.0\n",
      "episode: 2700, value: 1.0\n",
      "episode: 2730, value: 0.0\n",
      "episode: 2760, value: -438.0\n",
      "episode: 2790, value: -147.0\n",
      "episode: 2820, value: -57.0\n",
      "episode: 2850, value: -10.0\n",
      "episode: 2880, value: -56.0\n",
      "episode: 2910, value: -444.0\n",
      "episode: 2940, value: 1.0\n",
      "episode: 2970, value: -3.0\n",
      "episode: 3000, value: -50.0\n",
      "episode: 3030, value: 1.0\n",
      "episode: 3060, value: -191.0\n",
      "episode: 3090, value: -110.0\n",
      "episode: 3120, value: 0.0\n",
      "episode: 3150, value: -195.0\n",
      "episode: 3180, value: -436.0\n",
      "episode: 3210, value: -281.0\n",
      "episode: 3240, value: -100.0\n",
      "episode: 3270, value: -384.0\n",
      "episode: 3300, value: -3.0\n",
      "episode: 3330, value: 1.0\n",
      "episode: 3360, value: -306.0\n",
      "episode: 3390, value: -293.0\n",
      "episode: 3420, value: -251.0\n",
      "episode: 3450, value: -171.0\n",
      "episode: 3480, value: -344.0\n",
      "episode: 3510, value: 0.0\n",
      "episode: 3540, value: -147.0\n",
      "episode: 3570, value: -3.0\n",
      "episode: 3600, value: -263.0\n",
      "episode: 3630, value: -136.0\n",
      "episode: 3660, value: -317.0\n",
      "episode: 3690, value: -309.0\n",
      "episode: 3720, value: 0.0\n",
      "episode: 3750, value: 0.0\n",
      "episode: 3780, value: 1.0\n",
      "episode: 3810, value: -297.0\n",
      "episode: 3840, value: -269.0\n",
      "episode: 3870, value: -266.0\n",
      "episode: 3900, value: -4.0\n",
      "episode: 3930, value: 1.0\n",
      "episode: 3960, value: -190.0\n",
      "episode: 3990, value: -40.0\n",
      "episode: 4020, value: -147.0\n",
      "episode: 4050, value: -2.0\n",
      "episode: 4080, value: -230.0\n",
      "episode: 4110, value: -29.0\n",
      "episode: 4140, value: 1.0\n",
      "episode: 4170, value: -64.0\n",
      "episode: 4200, value: -203.0\n",
      "episode: 4230, value: -61.0\n",
      "episode: 4260, value: -210.0\n",
      "episode: 4290, value: -193.0\n",
      "episode: 4320, value: 0.0\n",
      "episode: 4350, value: -201.0\n",
      "episode: 4380, value: -178.0\n",
      "episode: 4410, value: -162.0\n",
      "episode: 4440, value: -206.0\n",
      "episode: 4470, value: -195.0\n",
      "episode: 4500, value: -195.0\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[15], line 16\u001b[0m\n\u001b[1;32m     14\u001b[0m step \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m0\u001b[39m\n\u001b[1;32m     15\u001b[0m \u001b[38;5;28;01mwhile\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m done:\n\u001b[0;32m---> 16\u001b[0m     action \u001b[38;5;241m=\u001b[39m \u001b[43magent\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtake_action\u001b[49m\u001b[43m(\u001b[49m\u001b[43mstate\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     17\u001b[0m     next_state, reward, done \u001b[38;5;241m=\u001b[39m gridworld\u001b[38;5;241m.\u001b[39mstep(state, action)\n\u001b[1;32m     18\u001b[0m     transiton_dict[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mstates\u001b[39m\u001b[38;5;124m\"\u001b[39m]\u001b[38;5;241m.\u001b[39mappend(state)\n",
      "Cell \u001b[0;32mIn[13], line 25\u001b[0m, in \u001b[0;36mActorCritic.take_action\u001b[0;34m(self, state)\u001b[0m\n\u001b[1;32m     23\u001b[0m probs \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mpolicy_net(state)\n\u001b[1;32m     24\u001b[0m action_dist  \u001b[38;5;241m=\u001b[39m torch\u001b[38;5;241m.\u001b[39mdistributions\u001b[38;5;241m.\u001b[39mCategorical(probs)\n\u001b[0;32m---> 25\u001b[0m action \u001b[38;5;241m=\u001b[39m \u001b[43maction_dist\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msample\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     26\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m action\u001b[38;5;241m.\u001b[39mitem()\n",
      "File \u001b[0;32m/opt/homebrew/Caskroom/miniconda/base/envs/rl/lib/python3.10/site-packages/torch/distributions/categorical.py:133\u001b[0m, in \u001b[0;36mCategorical.sample\u001b[0;34m(self, sample_shape)\u001b[0m\n\u001b[1;32m    131\u001b[0m     sample_shape \u001b[38;5;241m=\u001b[39m torch\u001b[38;5;241m.\u001b[39mSize(sample_shape)\n\u001b[1;32m    132\u001b[0m probs_2d \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mprobs\u001b[38;5;241m.\u001b[39mreshape(\u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_num_events)\n\u001b[0;32m--> 133\u001b[0m samples_2d \u001b[38;5;241m=\u001b[39m \u001b[43mtorch\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mmultinomial\u001b[49m\u001b[43m(\u001b[49m\u001b[43mprobs_2d\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43msample_shape\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mnumel\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m)\u001b[49m\u001b[38;5;241m.\u001b[39mT\n\u001b[1;32m    134\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m samples_2d\u001b[38;5;241m.\u001b[39mreshape(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_extended_shape(sample_shape))\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "max_v = -100\n",
    "max_step = 2000\n",
    "for i in range(num_episodes):\n",
    "    state = gridworld.reset()\n",
    "    done = False\n",
    "    episode_reward = 0\n",
    "    transiton_dict = {\n",
    "                \"states\": [],\n",
    "                \"actions\": [],\n",
    "                \"rewards\": [],\n",
    "                \"next_states\": [],\n",
    "                \"dones\": [],\n",
    "            }\n",
    "    step = 0\n",
    "    while not done:\n",
    "        action = agent.take_action(state)\n",
    "        next_state, reward, done = gridworld.step(state, action)\n",
    "        transiton_dict[\"states\"].append(state)\n",
    "        transiton_dict[\"actions\"].append(action)\n",
    "        transiton_dict[\"next_states\"].append(next_state)\n",
    "        transiton_dict[\"rewards\"].append(reward)\n",
    "        transiton_dict[\"dones\"].append(done)\n",
    "        state = next_state\n",
    "        episode_reward += reward\n",
    "        step += 1\n",
    "        if step >= max_step:\n",
    "            done = True\n",
    "\n",
    "    agent.update(transiton_dict)\n",
    "    if episode_reward >= max_v:\n",
    "        agent.save(\"model.pth\")\n",
    "        max_v = episode_reward\n",
    "    if i % 30 == 0:\n",
    "        print(f\"episode: {i}, value: {episode_reward}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([25, 5])\n",
      "[[[4.44375984e-02 4.43958454e-02 4.43958454e-02 4.43958454e-02\n",
      "   8.22374880e-01]\n",
      "  [2.31004003e-02 2.31004003e-02 2.31004003e-02 3.61869894e-02\n",
      "   8.94511759e-01]\n",
      "  [8.55546724e-03 8.55546724e-03 8.55546724e-03 1.85363796e-02\n",
      "   9.55797255e-01]\n",
      "  [2.78313062e-03 2.78313062e-03 2.78313062e-03 8.03983770e-03\n",
      "   9.83610749e-01]\n",
      "  [8.75701604e-04 8.75701604e-04 8.75701604e-04 3.28365574e-03\n",
      "   9.94089246e-01]]\n",
      "\n",
      " [[3.06193501e-01 1.19396493e-01 1.19396493e-01 1.19396493e-01\n",
      "   3.35617095e-01]\n",
      "  [1.78717017e-01 1.21543318e-01 1.21543318e-01 1.21543318e-01\n",
      "   4.56653118e-01]\n",
      "  [8.16551074e-02 6.80392608e-02 6.80392608e-02 7.85204768e-02\n",
      "   7.03745961e-01]\n",
      "  [2.77023390e-02 2.41663251e-02 2.41663251e-02 3.59019376e-02\n",
      "   8.88063073e-01]\n",
      "  [7.88011402e-03 7.21978815e-03 7.21978815e-03 1.38195762e-02\n",
      "   9.63860691e-01]]\n",
      "\n",
      " [[5.23327112e-01 1.09137416e-01 1.09137416e-01 1.09137416e-01\n",
      "   1.49260655e-01]\n",
      "  [3.89369875e-01 1.35797486e-01 1.35797486e-01 1.35797486e-01\n",
      "   2.03237683e-01]\n",
      "  [2.37722099e-01 1.33314878e-01 1.33314878e-01 1.33314878e-01\n",
      "   3.62333298e-01]\n",
      "  [1.08256109e-01 7.19307661e-02 7.19307661e-02 7.19307661e-02\n",
      "   6.75951600e-01]\n",
      "  [3.73103917e-02 2.57158391e-02 2.57158391e-02 2.57158391e-02\n",
      "   8.85542035e-01]]\n",
      "\n",
      " [[6.69573069e-01 7.85595477e-02 7.85595477e-02 7.85595477e-02\n",
      "   9.47483480e-02]\n",
      "  [5.67277253e-01 1.05708152e-01 1.05708152e-01 1.05708152e-01\n",
      "   1.15598418e-01]\n",
      "  [4.10610259e-01 1.22254282e-01 1.22254282e-01 1.22254282e-01\n",
      "   2.22626895e-01]\n",
      "  [2.56428480e-01 1.16357170e-01 1.16357170e-01 1.16357170e-01\n",
      "   3.94500047e-01]\n",
      "  [1.10943250e-01 5.76166809e-02 5.76166809e-02 5.76166809e-02\n",
      "   7.16206670e-01]]\n",
      "\n",
      " [[7.86707580e-01 5.21246493e-02 5.21246493e-02 5.21246493e-02\n",
      "   5.69183379e-02]\n",
      "  [7.02034295e-01 7.44914412e-02 7.44914412e-02 7.44914412e-02\n",
      "   7.44914412e-02]\n",
      "  [6.17205977e-01 9.26964357e-02 9.26964357e-02 9.26964357e-02\n",
      "   1.04704633e-01]\n",
      "  [4.35120940e-01 1.08180493e-01 1.08180493e-01 1.08180493e-01\n",
      "   2.40337521e-01]\n",
      "  [2.67483294e-01 9.52543244e-02 9.52543244e-02 9.52543244e-02\n",
      "   4.46753770e-01]]]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/j6/x5g6fdss0lx3bjtvj9_5cmwh0000gn/T/ipykernel_70278/1436956871.py:4: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
      "  best_net.load_state_dict(torch.load(\"model.pth\"))\n",
      "/var/folders/j6/x5g6fdss0lx3bjtvj9_5cmwh0000gn/T/ipykernel_70278/1436956871.py:8: DeprecationWarning: __array__ implementation doesn't accept a copy keyword, so passing copy=False failed. __array__ must implement 'dtype' and 'copy' keyword arguments.\n",
      "  q_tables = np.array(q_tables).reshape(rows, columns, action_dim)\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 350x350 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "gridworld_idx = [(i, j) for i in range(rows) for j in range(columns)]\n",
    "gridworld_idx =  torch.tensor(gridworld_idx,dtype=torch.float32)\n",
    "best_net = PolicyNet(state_dim, action_dim).to(device)\n",
    "best_net.load_state_dict(torch.load(\"model.pth\"))\n",
    "with torch.no_grad():\n",
    "    q_tables =best_net(gridworld_idx)\n",
    "    print(q_tables.shape)\n",
    "    q_tables = np.array(q_tables).reshape(rows, columns, action_dim)\n",
    "# print(f\"q_tables_shape:{q_tables.shape}\")\n",
    "print(q_tables)\n",
    "policy = np.argmax(q_tables, axis=2)\n",
    "gridworld.show_policy(policy)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "rl",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
