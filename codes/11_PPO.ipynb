{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import random\n",
    "import numpy as np\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from GridWorld_v1 import GridWorld_v1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 350x350 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "desc = rows = 5  # 记得行数和列数这里要同步改\n",
    "columns = 5\n",
    "desc = [\".....\",\".##..\",\"..#..\",\".#T#.\",\".#...\"]\n",
    "\n",
    "gridworld = GridWorld_v1(forbidden_area_score=-1, score=1,desc=desc) \n",
    "print(gridworld.animator.fig.get_facecolor())\n",
    "gridworld.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_advantage(gamma:int,lmbda:int,td_delta:torch.Tensor):\n",
    "    td_delta = td_delta.detach().numpy\n",
    "    advantage_list = []\n",
    "    advantage = 0\n",
    "    for delta in td_delta[::-1]:\n",
    "        advantage = gamma * lmbda *advantage+delta\n",
    "        advantage_list.append(advantage_list)\n",
    "    advantage_list.reverse()\n",
    "    return torch.tensor(advantage_list,dtype=torch.float)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class ValueNet(torch.nn.Module):\n",
    "    \"\"\"只有一层隐藏层的Q网络\"\"\"\n",
    "\n",
    "    def __init__(self,state_dim,hidden_dim):\n",
    "        super().__init__()\n",
    "        self.fc1 = torch.nn.Linear(state_dim, hidden_dim)\n",
    "        self.fc2 = torch.nn.Linear(hidden_dim, 1)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = F.relu(self.fc1(x))  # 隐藏层使用ReLU激活函数\n",
    "        return self.fc2(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class PolicyNet(torch.nn.Module):\n",
    "    \"\"\"只有一层隐藏层的Q网络\"\"\"\n",
    "\n",
    "    def __init__(self,state_dim,hidden_dim,action_dim):\n",
    "        super().__init__()\n",
    "        self.fc1 = torch.nn.Linear(state_dim, hidden_dim)\n",
    "        self.fc2 = torch.nn.Linear(hidden_dim, action_dim)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = F.relu(self.fc1(x))  # 隐藏层使用ReLU激活函数\n",
    "        x = F.relu(self.fc2(x))\n",
    "        return F.softmax(x,dim=1)  # 输出层不使用激活函数"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class PPO:\n",
    "    d"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "metadata": {},
   "outputs": [],
   "source": [
    "class ActorCritic:\n",
    "    def __init__(\n",
    "        self,\n",
    "        state_dim,\n",
    "        action_dim,\n",
    "        hidden_dim,\n",
    "        learning_rate,\n",
    "        critic_rate,\n",
    "        gamma,\n",
    "        device,\n",
    "    ) -> None:\n",
    "        self.action_dim = action_dim\n",
    "        self.policy_net = PolicyNet(state_dim, action_dim).to(device)\n",
    "        self.value_net = ValueNet(state_dim,hidden_dim)\n",
    "\n",
    "        self.actor_optimizer = torch.optim.Adam(self.policy_net.parameters(), lr=learning_rate)\n",
    "        self.critic_optimizer = torch.optim.Adam(self.value_net.parameters(), lr=critic_rate)\n",
    "        self.device = device\n",
    "        self.gamma = gamma\n",
    "\n",
    "    def take_action(self, state:tuple[ int,int ]):\n",
    "        state = torch.tensor([state], dtype=torch.float32).to(self.device)\n",
    "        probs = self.policy_net(state)\n",
    "        action_dist  = torch.distributions.Categorical(probs)\n",
    "        action = action_dist.sample()\n",
    "        return action.item()\n",
    "\n",
    "    def update(self, transiton_dict):\n",
    "        reward_list = transiton_dict[\"rewards\"]\n",
    "        state_list = transiton_dict[\"states\"]\n",
    "        action_list = transiton_dict[\"actions\"]\n",
    "        G = 0\n",
    "        states = torch.tensor(state_list, dtype=torch.float32).to(self.device)\n",
    "        actions = torch.tensor(action_list).view(-1,1).to(self.device)\n",
    "        next_states = torch.tensor(transiton_dict[\"next_states\"], dtype=torch.float32).to(self.device)\n",
    "        rewards = torch.tensor(reward_list,dtype=torch.float32).view(-1,1).to(self.device)\n",
    "        dones = torch.tensor(transiton_dict[\"dones\"], dtype=torch.float32).view(-1,1).to(self.device)\n",
    "        # print(f\"{states.shape=}\")\n",
    "        # print(f\"{actions.shape=}\")\n",
    "        # print(f\"{next_states.shape=}\")\n",
    "        # print(f\"{rewards.shape=}\")\n",
    "\n",
    "        td_target = rewards+self.gamma*self.value_net(next_states)*(1-dones)\n",
    "        # print(f\"{td_target.shape=}\")\n",
    "        td_delta = td_target - self.value_net(states)\n",
    "        # td_delta = -td_target + self.value_net(states)\n",
    "        action_pros = self.policy_net(states)\n",
    "        log_probs = torch.log(action_pros.gather( 1,actions ))\n",
    "        actor_loss = torch.mean(-log_probs*td_delta.detach())\n",
    "        critic_loss = torch.mean(F.mse_loss(self.value_net(states),td_target.detach()))\n",
    "        self.actor_optimizer.zero_grad() # 在这里就清零了\n",
    "        self.critic_optimizer.zero_grad() # 在这里就清零了\n",
    "        actor_loss.backward()\n",
    "        critic_loss.backward()\n",
    "        self.actor_optimizer.step()\n",
    "        self.critic_optimizer.step()\n",
    "\n",
    "    def save(self, path):\n",
    "        torch.save(self.policy_net.state_dict(), path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "metadata": {},
   "outputs": [],
   "source": [
    "lr = 1e-4\n",
    "\n",
    "num_episodes = 10000\n",
    "hidden_dim = 12\n",
    "gamma = 0.90\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "random.seed(0)\n",
    "np.random.seed(0)\n",
    "torch.manual_seed(0)\n",
    "state_dim = 2\n",
    "action_dim = 5\n",
    "hidden_dim = 32\n",
    "\n",
    "agent = ActorCritic(\n",
    "    state_dim,\n",
    "    action_dim,\n",
    "    hidden_dim,\n",
    "    lr,\n",
    "    lr,\n",
    "    gamma,\n",
    "    device,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "episode: 0, value: -5.0\n",
      "episode: 30, value: -6.0\n",
      "episode: 60, value: -7.0\n",
      "episode: 90, value: -14.0\n",
      "episode: 120, value: -14.0\n",
      "episode: 150, value: -37.0\n",
      "episode: 180, value: -36.0\n",
      "episode: 210, value: -9.0\n",
      "episode: 240, value: -33.0\n",
      "episode: 270, value: -5.0\n",
      "episode: 300, value: -19.0\n",
      "episode: 330, value: -8.0\n",
      "episode: 360, value: -7.0\n",
      "episode: 390, value: -36.0\n",
      "episode: 420, value: -135.0\n",
      "episode: 450, value: -45.0\n",
      "episode: 480, value: -46.0\n",
      "episode: 510, value: -57.0\n",
      "episode: 540, value: -10.0\n",
      "episode: 570, value: -55.0\n",
      "episode: 600, value: -12.0\n",
      "episode: 630, value: -87.0\n",
      "episode: 660, value: -11.0\n",
      "episode: 690, value: -154.0\n",
      "episode: 720, value: -44.0\n",
      "episode: 750, value: -7.0\n",
      "episode: 780, value: -105.0\n",
      "episode: 810, value: -74.0\n",
      "episode: 840, value: -22.0\n",
      "episode: 870, value: -2.0\n",
      "episode: 900, value: -123.0\n",
      "episode: 930, value: -33.0\n",
      "episode: 960, value: -203.0\n",
      "episode: 990, value: -147.0\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[108], line 15\u001b[0m\n\u001b[1;32m      6\u001b[0m transiton_dict \u001b[38;5;241m=\u001b[39m {\n\u001b[1;32m      7\u001b[0m             \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mstates\u001b[39m\u001b[38;5;124m\"\u001b[39m: [],\n\u001b[1;32m      8\u001b[0m             \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mactions\u001b[39m\u001b[38;5;124m\"\u001b[39m: [],\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m     11\u001b[0m             \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mdones\u001b[39m\u001b[38;5;124m\"\u001b[39m: [],\n\u001b[1;32m     12\u001b[0m         }\n\u001b[1;32m     14\u001b[0m \u001b[38;5;28;01mwhile\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m done:\n\u001b[0;32m---> 15\u001b[0m     action \u001b[38;5;241m=\u001b[39m \u001b[43magent\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtake_action\u001b[49m\u001b[43m(\u001b[49m\u001b[43mstate\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     16\u001b[0m     next_state, reward, done \u001b[38;5;241m=\u001b[39m gridworld\u001b[38;5;241m.\u001b[39mstep(state, action)\n\u001b[1;32m     17\u001b[0m     transiton_dict[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mstates\u001b[39m\u001b[38;5;124m\"\u001b[39m]\u001b[38;5;241m.\u001b[39mappend(state)\n",
      "Cell \u001b[0;32mIn[106], line 24\u001b[0m, in \u001b[0;36mActorCritic.take_action\u001b[0;34m(self, state)\u001b[0m\n\u001b[1;32m     22\u001b[0m state \u001b[38;5;241m=\u001b[39m torch\u001b[38;5;241m.\u001b[39mtensor([state], dtype\u001b[38;5;241m=\u001b[39mtorch\u001b[38;5;241m.\u001b[39mfloat32)\u001b[38;5;241m.\u001b[39mto(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdevice)\n\u001b[1;32m     23\u001b[0m probs \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mpolicy_net(state)\n\u001b[0;32m---> 24\u001b[0m action_dist  \u001b[38;5;241m=\u001b[39m \u001b[43mtorch\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdistributions\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mCategorical\u001b[49m\u001b[43m(\u001b[49m\u001b[43mprobs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     25\u001b[0m action \u001b[38;5;241m=\u001b[39m action_dist\u001b[38;5;241m.\u001b[39msample()\n\u001b[1;32m     26\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m action\u001b[38;5;241m.\u001b[39mitem()\n",
      "File \u001b[0;32m/opt/homebrew/Caskroom/miniconda/base/envs/rl/lib/python3.10/site-packages/torch/distributions/categorical.py:71\u001b[0m, in \u001b[0;36mCategorical.__init__\u001b[0;34m(self, probs, logits, validate_args)\u001b[0m\n\u001b[1;32m     67\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_num_events \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_param\u001b[38;5;241m.\u001b[39msize()[\u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m]\n\u001b[1;32m     68\u001b[0m batch_shape \u001b[38;5;241m=\u001b[39m (\n\u001b[1;32m     69\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_param\u001b[38;5;241m.\u001b[39msize()[:\u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m] \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_param\u001b[38;5;241m.\u001b[39mndimension() \u001b[38;5;241m>\u001b[39m \u001b[38;5;241m1\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m torch\u001b[38;5;241m.\u001b[39mSize()\n\u001b[1;32m     70\u001b[0m )\n\u001b[0;32m---> 71\u001b[0m \u001b[38;5;28;43msuper\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[38;5;21;43m__init__\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mbatch_shape\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mvalidate_args\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mvalidate_args\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/opt/homebrew/Caskroom/miniconda/base/envs/rl/lib/python3.10/site-packages/torch/distributions/distribution.py:68\u001b[0m, in \u001b[0;36mDistribution.__init__\u001b[0;34m(self, batch_shape, event_shape, validate_args)\u001b[0m\n\u001b[1;32m     66\u001b[0m     \u001b[38;5;28;01mcontinue\u001b[39;00m  \u001b[38;5;66;03m# skip checking lazily-constructed args\u001b[39;00m\n\u001b[1;32m     67\u001b[0m value \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mgetattr\u001b[39m(\u001b[38;5;28mself\u001b[39m, param)\n\u001b[0;32m---> 68\u001b[0m valid \u001b[38;5;241m=\u001b[39m \u001b[43mconstraint\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcheck\u001b[49m\u001b[43m(\u001b[49m\u001b[43mvalue\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     69\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m valid\u001b[38;5;241m.\u001b[39mall():\n\u001b[1;32m     70\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[1;32m     71\u001b[0m         \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mExpected parameter \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mparam\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m     72\u001b[0m         \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m(\u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28mtype\u001b[39m(value)\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__name__\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m of shape \u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28mtuple\u001b[39m(value\u001b[38;5;241m.\u001b[39mshape)\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m) \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m     75\u001b[0m         \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mbut found invalid values:\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;132;01m{\u001b[39;00mvalue\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m     76\u001b[0m     )\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "max_v = -100\n",
    "for i in range(num_episodes):\n",
    "    state = gridworld.reset((0,0))\n",
    "    done = False\n",
    "    episode_reward = 0\n",
    "    transiton_dict = {\n",
    "                \"states\": [],\n",
    "                \"actions\": [],\n",
    "                \"rewards\": [],\n",
    "                \"next_states\": [],\n",
    "                \"dones\": [],\n",
    "            }\n",
    "\n",
    "    while not done:\n",
    "        action = agent.take_action(state)\n",
    "        next_state, reward, done = gridworld.step(state, action)\n",
    "        transiton_dict[\"states\"].append(state)\n",
    "        transiton_dict[\"actions\"].append(action)\n",
    "        transiton_dict[\"next_states\"].append(next_state)\n",
    "        transiton_dict[\"rewards\"].append(reward)\n",
    "        transiton_dict[\"dones\"].append(done)\n",
    "        state = next_state\n",
    "        episode_reward += reward\n",
    "\n",
    "    agent.update(transiton_dict)\n",
    "    if episode_reward >= max_v:\n",
    "        agent.save(\"model.pth\")\n",
    "        max_v = episode_reward\n",
    "    if i % 30 == 0:\n",
    "        print(f\"episode: {i}, value: {episode_reward}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([25, 5])\n",
      "[[[1.19295483e-02 1.19295483e-02 1.19295483e-02 1.19617246e-02\n",
      "   9.52249646e-01]\n",
      "  [2.45269779e-02 2.45269779e-02 2.45269779e-02 1.74963832e-01\n",
      "   7.51455188e-01]\n",
      "  [1.48416767e-02 1.48416767e-02 1.48416767e-02 6.46645486e-01\n",
      "   3.08829486e-01]\n",
      "  [4.12431872e-03 4.12431872e-03 4.12431872e-03 8.64883602e-01\n",
      "   1.22743428e-01]\n",
      "  [9.66008694e-04 9.66008694e-04 9.66008694e-04 9.46236908e-01\n",
      "   5.08650094e-02]]\n",
      "\n",
      " [[4.37920764e-02 3.27090696e-02 3.27090696e-02 3.27090696e-02\n",
      "   8.58080685e-01]\n",
      "  [6.72020018e-02 6.72020018e-02 6.72020018e-02 3.11558336e-01\n",
      "   4.86835659e-01]\n",
      "  [2.59167608e-02 2.59167608e-02 2.59167608e-02 7.63620913e-01\n",
      "   1.58628881e-01]\n",
      "  [6.67767320e-03 6.67767320e-03 6.67767320e-03 9.11589324e-01\n",
      "   6.83777034e-02]\n",
      "  [1.52096350e-03 1.52096350e-03 1.52096350e-03 9.65133905e-01\n",
      "   3.03031858e-02]]\n",
      "\n",
      " [[1.85867518e-01 5.42221554e-02 5.42221554e-02 5.42221554e-02\n",
      "   6.51466072e-01]\n",
      "  [2.71935552e-01 9.95821878e-02 9.95821878e-02 2.63574690e-01\n",
      "   2.65325367e-01]\n",
      "  [6.72901124e-02 4.50679250e-02 4.50679250e-02 7.43928134e-01\n",
      "   9.86459330e-02]\n",
      "  [1.07611064e-02 1.05887046e-02 1.05887046e-02 9.26192641e-01\n",
      "   4.18688171e-02]\n",
      "  [2.38229916e-03 2.38229916e-03 2.38229916e-03 9.73024309e-01\n",
      "   1.98287349e-02]]\n",
      "\n",
      " [[4.90898430e-01 5.62497340e-02 5.62497340e-02 5.62497340e-02\n",
      "   3.40352386e-01]\n",
      "  [5.26803374e-01 8.93844664e-02 8.93844664e-02 1.35247648e-01\n",
      "   1.59180045e-01]\n",
      "  [2.15359360e-01 6.60889745e-02 6.60889745e-02 5.52228808e-01\n",
      "   1.00233935e-01]\n",
      "  [2.84304451e-02 1.63045526e-02 1.63045526e-02 9.07454371e-01\n",
      "   3.15061361e-02]\n",
      "  [4.65415558e-03 3.74385505e-03 3.74385505e-03 9.73803580e-01\n",
      "   1.40545545e-02]]\n",
      "\n",
      " [[7.00703979e-01 3.82339470e-02 3.82339470e-02 3.82339470e-02\n",
      "   1.84594169e-01]\n",
      "  [7.00245082e-01 6.24442101e-02 6.24442101e-02 6.33400306e-02\n",
      "   1.11526489e-01]\n",
      "  [4.82017756e-01 6.86418787e-02 6.86418787e-02 3.06137234e-01\n",
      "   7.45612532e-02]\n",
      "  [1.12186946e-01 3.01795378e-02 3.01795378e-02 7.90756702e-01\n",
      "   3.66973132e-02]\n",
      "  [1.17858248e-02 5.57794608e-03 5.57794608e-03 9.65882003e-01\n",
      "   1.11762313e-02]]]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/j6/x5g6fdss0lx3bjtvj9_5cmwh0000gn/T/ipykernel_26200/1436956871.py:4: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
      "  best_net.load_state_dict(torch.load(\"model.pth\"))\n",
      "/var/folders/j6/x5g6fdss0lx3bjtvj9_5cmwh0000gn/T/ipykernel_26200/1436956871.py:8: DeprecationWarning: __array__ implementation doesn't accept a copy keyword, so passing copy=False failed. __array__ must implement 'dtype' and 'copy' keyword arguments.\n",
      "  q_tables = np.array(q_tables).reshape(rows, columns, action_dim)\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 350x350 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "gridworld_idx = [(i, j) for i in range(rows) for j in range(columns)]\n",
    "gridworld_idx =  torch.tensor(gridworld_idx,dtype=torch.float32)\n",
    "best_net = PolicyNet(state_dim, action_dim).to(device)\n",
    "best_net.load_state_dict(torch.load(\"model.pth\"))\n",
    "with torch.no_grad():\n",
    "    q_tables =best_net(gridworld_idx)\n",
    "    print(q_tables.shape)\n",
    "    q_tables = np.array(q_tables).reshape(rows, columns, action_dim)\n",
    "# print(f\"q_tables_shape:{q_tables.shape}\")\n",
    "print(q_tables)\n",
    "policy = np.argmax(q_tables, axis=2)\n",
    "gridworld.show_policy(policy)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "rl",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
