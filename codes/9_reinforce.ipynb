{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 163,
   "metadata": {},
   "outputs": [],
   "source": [
    "import random\n",
    "import numpy as np\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from GridWorld_v1 import GridWorld_v1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 164,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 350x350 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "desc = rows = 5  # 记得行数和列数这里要同步改\n",
    "columns = 5\n",
    "desc = [\".....\",\".##..\",\"..#..\",\".#T#.\",\".#...\"]\n",
    "\n",
    "gridworld = GridWorld_v1(forbidden_area_score=-1, score=1,desc=desc) \n",
    "print(gridworld.animator.fig.get_facecolor())\n",
    "gridworld.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 165,
   "metadata": {},
   "outputs": [],
   "source": [
    "class PolicyNet(torch.nn.Module):\n",
    "    \"\"\"只有一层隐藏层的Q网络\"\"\"\n",
    "\n",
    "    def __init__(self,state_dim,action_dim):\n",
    "        super().__init__()\n",
    "        self.fc1 = torch.nn.Linear(state_dim, 64)\n",
    "        self.fc2 = torch.nn.Linear(64, action_dim)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = F.relu(self.fc1(x))  # 隐藏层使用ReLU激活函数\n",
    "        x = F.relu(self.fc2(x))\n",
    "        return F.softmax(x,dim=1)  # 输出层不使用激活函数"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 166,
   "metadata": {},
   "outputs": [],
   "source": [
    "class REINFORCE:\n",
    "    def __init__(\n",
    "        self,\n",
    "        state_dim,\n",
    "        action_dim,\n",
    "        learning_rate,\n",
    "        gamma,\n",
    "        device,\n",
    "    ) -> None:\n",
    "        self.action_dim = action_dim\n",
    "        self.policy_net = PolicyNet(state_dim, action_dim).to(device)\n",
    "\n",
    "        self.optimizer = torch.optim.Adam(self.policy_net.parameters(), lr=learning_rate)\n",
    "        # self.scheduler = torch.optim.lr_scheduler.StepLR(self.optimizer, step_size=1000, gamma=0.9)\n",
    "        self.device = device\n",
    "        self.gamma = gamma\n",
    "\n",
    "    def take_action(self, state:tuple[ int,int ]):\n",
    "        # print(f\"{state = }\")\n",
    "        # print(self.policy_net(torch.tensor( state , dtype=torch.float32).to(self.device)))\n",
    "        state = torch.tensor([ state ], dtype=torch.float32).to(self.device)\n",
    "        probs = self.policy_net(state)\n",
    "        # print(f\"{probs.shape=}\")\n",
    "        # print(f\"{probs}\")\n",
    "        action_dist = torch.distributions.Categorical(probs)\n",
    "        # print(action_dist)\n",
    "        action = action_dist.sample()\n",
    "        return action.item()\n",
    "\n",
    "    def update(self, transiton_dict):\n",
    "        reward_list = transiton_dict[\"rewards\"]\n",
    "        state_list = transiton_dict[\"states\"]\n",
    "        action_list = transiton_dict[\"actions\"]\n",
    "        G = 0\n",
    "        self.optimizer.zero_grad() # 在这里就清零了\n",
    "        for i in reversed(range(len(reward_list))):\n",
    "            state = torch.tensor([state_list[i]], dtype=torch.float32).to(self.device)\n",
    "            # print(f\"{state=}\")\n",
    "            action = torch.tensor(action_list[i]).view(-1,1).to(self.device)\n",
    "            # print(f\"{action=}\")\n",
    "            # print(f\"{action.shape=}\")\n",
    "            action_pro = self.policy_net(state)\n",
    "            # print(f\"{action_pro.shape=}\")\n",
    "            log_prob = torch.log(action_pro.gather( 1,action ))\n",
    "            G = self.gamma * G + reward_list[i]\n",
    "            # print(f\"{log_prob=}\")\n",
    "            loss = -log_prob * G\n",
    "            loss.backward()\n",
    "        self.optimizer.step()\n",
    "\n",
    "    def save(self, path):\n",
    "        torch.save(self.policy_net.state_dict(), path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 167,
   "metadata": {},
   "outputs": [],
   "source": [
    "lr = 1e-4\n",
    "num_episodes = 10000\n",
    "hidden_dim = 12\n",
    "gamma = 0.98\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "random.seed(0)\n",
    "np.random.seed(0)\n",
    "torch.manual_seed(0)\n",
    "state_dim = 2\n",
    "action_dim = 5\n",
    "\n",
    "agent = REINFORCE(\n",
    "    state_dim, action_dim, lr,gamma, device\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 168,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2"
      ]
     },
     "execution_count": 168,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "agent.take_action((1,1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 169,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "episode: 0, value: -10.0\n",
      "episode: 30, value: -23.0\n",
      "episode: 60, value: -7.0\n",
      "episode: 90, value: -33.0\n",
      "episode: 120, value: -3.0\n",
      "episode: 150, value: -58.0\n",
      "episode: 180, value: -40.0\n",
      "episode: 210, value: -42.0\n",
      "episode: 240, value: -9.0\n",
      "episode: 270, value: -6.0\n",
      "episode: 300, value: -12.0\n",
      "episode: 330, value: -35.0\n",
      "episode: 360, value: -18.0\n",
      "episode: 390, value: -11.0\n",
      "episode: 420, value: -13.0\n",
      "episode: 450, value: -20.0\n",
      "episode: 480, value: 0.0\n",
      "episode: 510, value: -51.0\n",
      "episode: 540, value: -36.0\n",
      "episode: 570, value: -9.0\n",
      "episode: 600, value: -17.0\n",
      "episode: 630, value: -6.0\n",
      "episode: 660, value: -10.0\n",
      "episode: 690, value: -11.0\n",
      "episode: 720, value: -30.0\n",
      "episode: 750, value: -14.0\n",
      "episode: 780, value: -10.0\n",
      "episode: 810, value: -5.0\n",
      "episode: 840, value: -12.0\n",
      "episode: 870, value: -7.0\n",
      "episode: 900, value: -12.0\n",
      "episode: 930, value: -6.0\n",
      "episode: 960, value: -2.0\n",
      "episode: 990, value: -6.0\n",
      "episode: 1020, value: -10.0\n",
      "episode: 1050, value: -13.0\n",
      "episode: 1080, value: -72.0\n",
      "episode: 1110, value: -16.0\n",
      "episode: 1140, value: -43.0\n",
      "episode: 1170, value: -32.0\n",
      "episode: 1200, value: -7.0\n",
      "episode: 1230, value: -11.0\n",
      "episode: 1260, value: -9.0\n",
      "episode: 1290, value: -12.0\n",
      "episode: 1320, value: -23.0\n",
      "episode: 1350, value: -18.0\n",
      "episode: 1380, value: -9.0\n",
      "episode: 1410, value: -29.0\n",
      "episode: 1440, value: -36.0\n",
      "episode: 1470, value: -1.0\n",
      "episode: 1500, value: -10.0\n",
      "episode: 1530, value: -39.0\n",
      "episode: 1560, value: -60.0\n",
      "episode: 1590, value: -7.0\n",
      "episode: 1620, value: -19.0\n",
      "episode: 1650, value: -33.0\n",
      "episode: 1680, value: -19.0\n",
      "episode: 1710, value: -6.0\n",
      "episode: 1740, value: -9.0\n",
      "episode: 1770, value: -29.0\n",
      "episode: 1800, value: -28.0\n",
      "episode: 1830, value: -8.0\n",
      "episode: 1860, value: -6.0\n",
      "episode: 1890, value: -27.0\n",
      "episode: 1920, value: -31.0\n",
      "episode: 1950, value: -15.0\n",
      "episode: 1980, value: -13.0\n",
      "episode: 2010, value: -1.0\n",
      "episode: 2040, value: -14.0\n",
      "episode: 2070, value: -9.0\n",
      "episode: 2100, value: -8.0\n",
      "episode: 2130, value: -24.0\n",
      "episode: 2160, value: -5.0\n",
      "episode: 2190, value: -7.0\n",
      "episode: 2220, value: -4.0\n",
      "episode: 2250, value: -16.0\n",
      "episode: 2280, value: -8.0\n",
      "episode: 2310, value: -4.0\n",
      "episode: 2340, value: -14.0\n",
      "episode: 2370, value: -46.0\n",
      "episode: 2400, value: -49.0\n",
      "episode: 2430, value: -36.0\n",
      "episode: 2460, value: 0.0\n",
      "episode: 2490, value: -13.0\n",
      "episode: 2520, value: -15.0\n",
      "episode: 2550, value: -41.0\n",
      "episode: 2580, value: -20.0\n",
      "episode: 2610, value: -22.0\n",
      "episode: 2640, value: -10.0\n",
      "episode: 2670, value: -60.0\n",
      "episode: 2700, value: -6.0\n",
      "episode: 2730, value: -35.0\n",
      "episode: 2760, value: -11.0\n",
      "episode: 2790, value: -8.0\n",
      "episode: 2820, value: -8.0\n",
      "episode: 2850, value: -4.0\n",
      "episode: 2880, value: -8.0\n",
      "episode: 2910, value: -6.0\n",
      "episode: 2940, value: -18.0\n",
      "episode: 2970, value: 0.0\n",
      "episode: 3000, value: -30.0\n",
      "episode: 3030, value: -13.0\n",
      "episode: 3060, value: -11.0\n",
      "episode: 3090, value: -11.0\n",
      "episode: 3120, value: -24.0\n",
      "episode: 3150, value: -16.0\n",
      "episode: 3180, value: -23.0\n",
      "episode: 3210, value: -13.0\n",
      "episode: 3240, value: -32.0\n",
      "episode: 3270, value: -5.0\n",
      "episode: 3300, value: -16.0\n",
      "episode: 3330, value: -34.0\n",
      "episode: 3360, value: -16.0\n",
      "episode: 3390, value: -34.0\n",
      "episode: 3420, value: -16.0\n",
      "episode: 3450, value: -4.0\n",
      "episode: 3480, value: -4.0\n",
      "episode: 3510, value: -18.0\n",
      "episode: 3540, value: -25.0\n",
      "episode: 3570, value: -5.0\n",
      "episode: 3600, value: -36.0\n",
      "episode: 3630, value: -46.0\n",
      "episode: 3660, value: -26.0\n",
      "episode: 3690, value: -26.0\n",
      "episode: 3720, value: -10.0\n",
      "episode: 3750, value: -27.0\n",
      "episode: 3780, value: -21.0\n",
      "episode: 3810, value: -23.0\n",
      "episode: 3840, value: -23.0\n",
      "episode: 3870, value: -26.0\n",
      "episode: 3900, value: -15.0\n",
      "episode: 3930, value: -60.0\n",
      "episode: 3960, value: -28.0\n",
      "episode: 3990, value: -14.0\n",
      "episode: 4020, value: -30.0\n",
      "episode: 4050, value: -17.0\n",
      "episode: 4080, value: -3.0\n",
      "episode: 4110, value: -3.0\n",
      "episode: 4140, value: -14.0\n",
      "episode: 4170, value: -16.0\n",
      "episode: 4200, value: -45.0\n",
      "episode: 4230, value: -14.0\n",
      "episode: 4260, value: -8.0\n",
      "episode: 4290, value: -103.0\n",
      "episode: 4320, value: -23.0\n",
      "episode: 4350, value: -27.0\n",
      "episode: 4380, value: -10.0\n",
      "episode: 4410, value: -9.0\n",
      "episode: 4440, value: -9.0\n",
      "episode: 4470, value: -12.0\n",
      "episode: 4500, value: -4.0\n",
      "episode: 4530, value: -23.0\n",
      "episode: 4560, value: -20.0\n",
      "episode: 4590, value: -12.0\n",
      "episode: 4620, value: -4.0\n",
      "episode: 4650, value: -26.0\n",
      "episode: 4680, value: -37.0\n",
      "episode: 4710, value: -28.0\n",
      "episode: 4740, value: -4.0\n",
      "episode: 4770, value: -31.0\n",
      "episode: 4800, value: -13.0\n",
      "episode: 4830, value: -5.0\n",
      "episode: 4860, value: -29.0\n",
      "episode: 4890, value: -32.0\n",
      "episode: 4920, value: -7.0\n",
      "episode: 4950, value: -4.0\n",
      "episode: 4980, value: -3.0\n",
      "episode: 5010, value: -5.0\n",
      "episode: 5040, value: -31.0\n",
      "episode: 5070, value: -5.0\n",
      "episode: 5100, value: -5.0\n",
      "episode: 5130, value: -7.0\n",
      "episode: 5160, value: -17.0\n",
      "episode: 5190, value: -31.0\n",
      "episode: 5220, value: -7.0\n",
      "episode: 5250, value: -23.0\n",
      "episode: 5280, value: -12.0\n",
      "episode: 5310, value: -14.0\n",
      "episode: 5340, value: -11.0\n",
      "episode: 5370, value: -8.0\n",
      "episode: 5400, value: -54.0\n",
      "episode: 5430, value: -4.0\n",
      "episode: 5460, value: -2.0\n",
      "episode: 5490, value: -19.0\n",
      "episode: 5520, value: -11.0\n",
      "episode: 5550, value: -16.0\n",
      "episode: 5580, value: -25.0\n",
      "episode: 5610, value: -21.0\n",
      "episode: 5640, value: -10.0\n",
      "episode: 5670, value: -68.0\n",
      "episode: 5700, value: -12.0\n",
      "episode: 5730, value: -2.0\n",
      "episode: 5760, value: -6.0\n",
      "episode: 5790, value: -3.0\n",
      "episode: 5820, value: -19.0\n",
      "episode: 5850, value: -8.0\n",
      "episode: 5880, value: -25.0\n",
      "episode: 5910, value: -22.0\n",
      "episode: 5940, value: -14.0\n",
      "episode: 5970, value: -15.0\n",
      "episode: 6000, value: -7.0\n",
      "episode: 6030, value: -10.0\n",
      "episode: 6060, value: -7.0\n",
      "episode: 6090, value: -8.0\n",
      "episode: 6120, value: -4.0\n",
      "episode: 6150, value: -46.0\n",
      "episode: 6180, value: -13.0\n",
      "episode: 6210, value: -11.0\n",
      "episode: 6240, value: -2.0\n",
      "episode: 6270, value: -15.0\n",
      "episode: 6300, value: -8.0\n",
      "episode: 6330, value: -5.0\n",
      "episode: 6360, value: -7.0\n",
      "episode: 6390, value: -18.0\n",
      "episode: 6420, value: -17.0\n",
      "episode: 6450, value: -52.0\n",
      "episode: 6480, value: -12.0\n",
      "episode: 6510, value: -9.0\n",
      "episode: 6540, value: -17.0\n",
      "episode: 6570, value: -6.0\n",
      "episode: 6600, value: -94.0\n",
      "episode: 6630, value: -6.0\n",
      "episode: 6660, value: -8.0\n",
      "episode: 6690, value: -19.0\n",
      "episode: 6720, value: -9.0\n",
      "episode: 6750, value: -22.0\n",
      "episode: 6780, value: -17.0\n",
      "episode: 6810, value: -1.0\n",
      "episode: 6840, value: -10.0\n",
      "episode: 6870, value: -9.0\n",
      "episode: 6900, value: -17.0\n",
      "episode: 6930, value: -22.0\n",
      "episode: 6960, value: -19.0\n",
      "episode: 6990, value: -6.0\n",
      "episode: 7020, value: -8.0\n",
      "episode: 7050, value: -10.0\n",
      "episode: 7080, value: -12.0\n",
      "episode: 7110, value: 0.0\n",
      "episode: 7140, value: -11.0\n",
      "episode: 7170, value: -5.0\n",
      "episode: 7200, value: -40.0\n",
      "episode: 7230, value: -5.0\n",
      "episode: 7260, value: -18.0\n",
      "episode: 7290, value: -6.0\n",
      "episode: 7320, value: -6.0\n",
      "episode: 7350, value: -4.0\n",
      "episode: 7380, value: -12.0\n",
      "episode: 7410, value: -29.0\n",
      "episode: 7440, value: -21.0\n",
      "episode: 7470, value: -13.0\n",
      "episode: 7500, value: -5.0\n",
      "episode: 7530, value: -1.0\n",
      "episode: 7560, value: -9.0\n",
      "episode: 7590, value: -60.0\n",
      "episode: 7620, value: -7.0\n",
      "episode: 7650, value: -2.0\n",
      "episode: 7680, value: 0.0\n",
      "episode: 7710, value: -17.0\n",
      "episode: 7740, value: -16.0\n",
      "episode: 7770, value: -2.0\n",
      "episode: 7800, value: -8.0\n",
      "episode: 7830, value: -5.0\n",
      "episode: 7860, value: -16.0\n",
      "episode: 7890, value: -5.0\n",
      "episode: 7920, value: -7.0\n",
      "episode: 7950, value: -3.0\n",
      "episode: 7980, value: -1.0\n",
      "episode: 8010, value: -14.0\n",
      "episode: 8040, value: -36.0\n",
      "episode: 8070, value: -3.0\n",
      "episode: 8100, value: -5.0\n",
      "episode: 8130, value: -12.0\n",
      "episode: 8160, value: -16.0\n",
      "episode: 8190, value: -26.0\n",
      "episode: 8220, value: -7.0\n",
      "episode: 8250, value: -23.0\n",
      "episode: 8280, value: -39.0\n",
      "episode: 8310, value: -18.0\n",
      "episode: 8340, value: -24.0\n",
      "episode: 8370, value: -7.0\n",
      "episode: 8400, value: -5.0\n",
      "episode: 8430, value: -40.0\n",
      "episode: 8460, value: -5.0\n",
      "episode: 8490, value: -43.0\n",
      "episode: 8520, value: -11.0\n",
      "episode: 8550, value: -5.0\n",
      "episode: 8580, value: -8.0\n",
      "episode: 8610, value: -13.0\n",
      "episode: 8640, value: -18.0\n",
      "episode: 8670, value: -29.0\n",
      "episode: 8700, value: -2.0\n",
      "episode: 8730, value: -4.0\n",
      "episode: 8760, value: -6.0\n",
      "episode: 8790, value: -19.0\n",
      "episode: 8820, value: -12.0\n",
      "episode: 8850, value: -11.0\n",
      "episode: 8880, value: -4.0\n",
      "episode: 8910, value: -5.0\n",
      "episode: 8940, value: -17.0\n",
      "episode: 8970, value: -8.0\n",
      "episode: 9000, value: -18.0\n",
      "episode: 9030, value: 0.0\n",
      "episode: 9060, value: -14.0\n",
      "episode: 9090, value: -4.0\n",
      "episode: 9120, value: -6.0\n",
      "episode: 9150, value: -38.0\n",
      "episode: 9180, value: -22.0\n",
      "episode: 9210, value: -22.0\n",
      "episode: 9240, value: -14.0\n",
      "episode: 9270, value: -11.0\n",
      "episode: 9300, value: -25.0\n",
      "episode: 9330, value: -4.0\n",
      "episode: 9360, value: -7.0\n",
      "episode: 9390, value: 0.0\n",
      "episode: 9420, value: -3.0\n",
      "episode: 9450, value: -8.0\n",
      "episode: 9480, value: -9.0\n",
      "episode: 9510, value: -23.0\n",
      "episode: 9540, value: -5.0\n",
      "episode: 9570, value: -2.0\n",
      "episode: 9600, value: -14.0\n",
      "episode: 9630, value: -29.0\n",
      "episode: 9660, value: -10.0\n",
      "episode: 9690, value: -3.0\n",
      "episode: 9720, value: -18.0\n",
      "episode: 9750, value: -7.0\n",
      "episode: 9780, value: -9.0\n",
      "episode: 9810, value: -7.0\n",
      "episode: 9840, value: -8.0\n",
      "episode: 9870, value: -7.0\n",
      "episode: 9900, value: -13.0\n",
      "episode: 9930, value: -41.0\n",
      "episode: 9960, value: -14.0\n",
      "episode: 9990, value: -77.0\n"
     ]
    }
   ],
   "source": [
    "max_v = -100\n",
    "for i in range(num_episodes):\n",
    "    state = gridworld.reset((0,0))\n",
    "    done = False\n",
    "    episode_reward = 0\n",
    "    transiton_dict = {\n",
    "                \"states\": [],\n",
    "                \"actions\": [],\n",
    "                \"rewards\": [],\n",
    "                \"next_states\": [],\n",
    "                \"dones\": [],\n",
    "            }\n",
    "\n",
    "    while not done:\n",
    "        action = agent.take_action(state)\n",
    "        next_state, reward, done = gridworld.step(state, action)\n",
    "        transiton_dict[\"states\"].append(state)\n",
    "        transiton_dict[\"actions\"].append(action)\n",
    "        transiton_dict[\"next_states\"].append(next_state)\n",
    "        transiton_dict[\"rewards\"].append(reward)\n",
    "        transiton_dict[\"dones\"].append(done)\n",
    "        state = next_state\n",
    "        episode_reward += reward\n",
    "\n",
    "    agent.update(transiton_dict)\n",
    "    if episode_reward >= max_v:\n",
    "        agent.save(\"model.pth\")\n",
    "        max_v = episode_reward\n",
    "    if i % 30 == 0:\n",
    "        print(f\"episode: {i}, value: {episode_reward}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 170,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([25, 5])\n",
      "[[[0.15332241 0.15332241 0.3844706  0.15332241 0.15556216]\n",
      "  [0.14312604 0.14312604 0.38907006 0.14312604 0.18155184]\n",
      "  [0.13116772 0.13116772 0.426185   0.13116772 0.18031184]\n",
      "  [0.11012918 0.11012918 0.48886257 0.11012918 0.1807499 ]\n",
      "  [0.08985325 0.08985325 0.5501461  0.08985325 0.18029414]]\n",
      "\n",
      " [[0.17700684 0.17700684 0.2919726  0.17700684 0.17700684]\n",
      "  [0.16428666 0.16428666 0.33231923 0.16428666 0.17482086]\n",
      "  [0.1495112  0.1495112  0.36811146 0.1495112  0.18335497]\n",
      "  [0.12900217 0.12900217 0.4271137  0.12900217 0.18587978]\n",
      "  [0.10736965 0.10736965 0.48905006 0.10736965 0.18884097]]\n",
      "\n",
      " [[0.1886522  0.1886522  0.2453912  0.1886522  0.1886522 ]\n",
      "  [0.18553631 0.18553631 0.25785482 0.18553631 0.18553631]\n",
      "  [0.16724914 0.16724914 0.31156036 0.16724914 0.1866922 ]\n",
      "  [0.14959396 0.14959396 0.3580983  0.14959396 0.19311982]\n",
      "  [0.12814504 0.12814504 0.4212876  0.12814504 0.19427729]]\n",
      "\n",
      " [[0.19719982 0.19719982 0.21120073 0.19719982 0.19719982]\n",
      "  [0.19894943 0.19894943 0.20420235 0.19894943 0.19894943]\n",
      "  [0.18775313 0.18775313 0.24898747 0.18775313 0.18775313]\n",
      "  [0.16738187 0.16738187 0.29834378 0.16738187 0.1995107 ]\n",
      "  [0.14783989 0.14783989 0.35188934 0.14783989 0.20459098]]\n",
      "\n",
      " [[0.2        0.2        0.2        0.2        0.2       ]\n",
      "  [0.2        0.2        0.2        0.2        0.2       ]\n",
      "  [0.2        0.2        0.2        0.2        0.2       ]\n",
      "  [0.18937905 0.18937905 0.2402776  0.18937905 0.19158532]\n",
      "  [0.16727358 0.16727358 0.28527668 0.16727358 0.21290249]]]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/j6/x5g6fdss0lx3bjtvj9_5cmwh0000gn/T/ipykernel_25527/1436956871.py:4: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
      "  best_net.load_state_dict(torch.load(\"model.pth\"))\n",
      "/var/folders/j6/x5g6fdss0lx3bjtvj9_5cmwh0000gn/T/ipykernel_25527/1436956871.py:8: DeprecationWarning: __array__ implementation doesn't accept a copy keyword, so passing copy=False failed. __array__ must implement 'dtype' and 'copy' keyword arguments.\n",
      "  q_tables = np.array(q_tables).reshape(rows, columns, action_dim)\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 350x350 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "gridworld_idx = [(i, j) for i in range(rows) for j in range(columns)]\n",
    "gridworld_idx =  torch.tensor(gridworld_idx,dtype=torch.float32)\n",
    "best_net = PolicyNet(state_dim, action_dim).to(device)\n",
    "best_net.load_state_dict(torch.load(\"model.pth\"))\n",
    "with torch.no_grad():\n",
    "    q_tables =best_net(gridworld_idx)\n",
    "    print(q_tables.shape)\n",
    "    q_tables = np.array(q_tables).reshape(rows, columns, action_dim)\n",
    "# print(f\"q_tables_shape:{q_tables.shape}\")\n",
    "print(q_tables)\n",
    "policy = np.argmax(q_tables, axis=2)\n",
    "gridworld.show_policy(policy)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "rl",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
